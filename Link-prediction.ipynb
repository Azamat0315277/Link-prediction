{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Prediction using Movielens dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch_geometric\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "import tqdm\n",
    "from torch.nn import  ReLU\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download additional libraries\n",
    "%pip install torch-scatter -f https://data.pyg.org/whl/torch-${torch.__version__}.html\n",
    "%pip install torch-sparse -f https://data.pyg.org/whl/torch-${torch.__version__}.html\n",
    "%pip install pyg-lib -f https://data.pyg.org/whl/nightly/torch-${torch.__version__}.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import download_url, extract_zip\n",
    "\n",
    "url = \"https://files.grouplens.org/datasets/movielens/ml-latest.zip\"\n",
    "extract_zip(download_url(url, \".\"), \".\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movies_path = './ml-latest-small/movies.csv'\n",
    "ratings_path = './ml-latest-small/ratings.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check and prerocess movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title  \\\n",
       "movieId                                       \n",
       "1                          Toy Story (1995)   \n",
       "2                            Jumanji (1995)   \n",
       "3                   Grumpier Old Men (1995)   \n",
       "4                  Waiting to Exhale (1995)   \n",
       "5        Father of the Bride Part II (1995)   \n",
       "\n",
       "                                              genres  \n",
       "movieId                                               \n",
       "1        Adventure|Animation|Children|Comedy|Fantasy  \n",
       "2                         Adventure|Children|Fantasy  \n",
       "3                                     Comedy|Romance  \n",
       "4                               Comedy|Drama|Romance  \n",
       "5                                             Comedy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load movie data\n",
    "movies_df = pd.read_csv(movies_path, index_col=\"movieId\")\n",
    "\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         (no genres listed)  Action  Adventure  Animation  Children  Comedy  \\\n",
       "movieId                                                                       \n",
       "1                         0       0          1          1         1       1   \n",
       "2                         0       0          1          0         1       0   \n",
       "3                         0       0          0          0         0       1   \n",
       "4                         0       0          0          0         0       1   \n",
       "5                         0       0          0          0         0       1   \n",
       "\n",
       "         Crime  Documentary  Drama  Fantasy  Film-Noir  Horror  IMAX  Musical  \\\n",
       "movieId                                                                         \n",
       "1            0            0      0        1          0       0     0        0   \n",
       "2            0            0      0        1          0       0     0        0   \n",
       "3            0            0      0        0          0       0     0        0   \n",
       "4            0            0      1        0          0       0     0        0   \n",
       "5            0            0      0        0          0       0     0        0   \n",
       "\n",
       "         Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "movieId                                                    \n",
       "1              0        0       0         0    0        0  \n",
       "2              0        0       0         0    0        0  \n",
       "3              0        1       0         0    0        0  \n",
       "4              0        1       0         0    0        0  \n",
       "5              0        0       0         0    0        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split genres and convert into indicator variables (create dummy variables)\n",
    "genres = movies_df['genres'].str.get_dummies(\"|\")\n",
    "genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User genres as movie input features (node features)\n",
    "movie_features = torch.from_numpy(genres.values).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>mappedID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  mappedID\n",
       "0        1         0\n",
       "1        2         1\n",
       "2        3         2\n",
       "3        4         3\n",
       "4        5         4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mapping from unique movie indices to range[0, num_movie_nodes]\n",
    "unique_movie_id = pd.DataFrame(data={\n",
    "    'movieId': movies_df.index,\n",
    "    \"mappedID\": pd.RangeIndex(len(movies_df)),\n",
    "})\n",
    "unique_movie_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check and preprocess ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ratings data\n",
    "ratings_df = pd.read_csv(ratings_path)\n",
    "ratings_df = ratings_df[ratings_df['rating'].isin([4.0, 4.5, 5.0])].copy()\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "4.0    26818\n",
       "5.0    13211\n",
       "4.5     8551\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>mappedID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  mappedID\n",
       "0       1         0\n",
       "1       2         1\n",
       "2       3         2\n",
       "3       4         3\n",
       "4       5         4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mapping from unique user indices to range [0, num_user_nodes]\n",
    "unique_user_id = ratings_df['userId'].unique()\n",
    "unique_user_id = pd.DataFrame(data={\n",
    "    'userId': unique_user_id,\n",
    "    \"mappedID\": pd.RangeIndex(len(unique_user_id)),\n",
    "})\n",
    "unique_user_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating `edge_index` in COO Format for User-Movie Relationships "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform merge to obtain the edges from users and movies\n",
    "ratings_user_id = pd.merge(ratings_df['userId'], unique_user_id,\n",
    "                            on='userId', how='left')\n",
    "ratings_user_id = torch.from_numpy(ratings_user_id['mappedID'].values)\n",
    "\n",
    "ratings_movie_id = pd.merge(ratings_df['movieId'], unique_movie_id,\n",
    "                            on='movieId', how='left')\n",
    "ratings_movie_id = torch.from_numpy(ratings_movie_id['mappedID'].values)\n",
    "\n",
    "# Create `edge_index` in COO format following PyG semantics\n",
    "edge_index_user_to_movie = torch.stack([ratings_user_id, ratings_movie_id], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of user IDs to consecutive values:\n",
      "==========================================\n",
      "   userId  mappedID\n",
      "0       1         0\n",
      "1       2         1\n",
      "2       3         2\n",
      "3       4         3\n",
      "4       5         4\n"
     ]
    }
   ],
   "source": [
    "print(\"Mapping of user IDs to consecutive values:\")\n",
    "print(\"==========================================\")\n",
    "print(unique_user_id.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of movie IDs to consecutive values:\n",
      "===========================================\n",
      "   movieId  mappedID\n",
      "0        1         0\n",
      "1        2         1\n",
      "2        3         2\n",
      "3        4         3\n",
      "4        5         4\n"
     ]
    }
   ],
   "source": [
    "print(\"Mapping of movie IDs to consecutive values:\")\n",
    "print(\"===========================================\")\n",
    "print(unique_movie_id.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final edge indices pointing from users to movies:\n",
      "=================================================\n",
      "tensor([[   0,    0,    0,  ...,  608,  608,  608],\n",
      "        [   0,    2,    5,  ..., 9461, 9462, 9463]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Final edge indices pointing from users to movies:\")\n",
    "print(\"=================================================\")\n",
    "print(edge_index_user_to_movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating graph based HeteroData (where nodes have different origins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "\n",
    "# Save node indices\n",
    "data['user'].node_id = torch.arange(len(unique_user_id))\n",
    "data['movie'].node_id = torch.arange(len(movies_df))\n",
    "\n",
    "# Add the node features and edge indices\n",
    "data['movie'].x = movie_features\n",
    "\n",
    "data['user', 'rates', 'movie'].edge_index = edge_index_user_to_movie\n",
    "\n",
    "# Also need to make sure add the reverse adges from movies to users\n",
    "# in order to let a GNN model be able to pass messages in both directions.\n",
    "# For this use `ToUndirected()` transform \n",
    "\n",
    "data = T.ToUndirected()(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Edge-level Training Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    disjoint_train_ratio = 0.3,\n",
    "    neg_sampling_ratio = 2.0,\n",
    "    add_negative_train_samples=False,\n",
    "    edge_types = ('user', 'rates', 'movie'),\n",
    "    rev_edge_types = ('movie', 'rev_rates', 'user'),\n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define seed edges:\n",
    "edge_label_index = train_data[\"user\", \"rates\", \"movie\"].edge_label_index\n",
    "edge_label = train_data[\"user\", \"rates\", \"movie\"].edge_label\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,  \n",
    "    num_neighbors=[20, 10],  \n",
    "    neg_sampling_ratio=2.0,  \n",
    "    edge_label_index=((\"user\", \"rates\", \"movie\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=524288, # OPtional default= 128\n",
    "    shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_label_index = val_data['user', 'rates', 'movie'].edge_label_index\n",
    "edge_label = val_data['user', 'rates', 'movie'].edge_label\n",
    "\n",
    "val_loader = LinkNeighborLoader(\n",
    "    data=val_data,\n",
    "    num_neighbors = [20, 10],\n",
    "    edge_label_index = (('user', 'rates', 'movie'), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=524288,\n",
    "    shuffle=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "def precision_at_k(y_true, y_pred, k):\n",
    "    # Sort by predicted values\n",
    "    idx = np.argsort(y_pred)[::-1]\n",
    "    y_true = y_true[idx]\n",
    "    \n",
    "    # Get top k predictions\n",
    "    y_true_at_k = y_true[:k]\n",
    "    \n",
    "    return np.sum(y_true_at_k) / k\n",
    "\n",
    "def normalized_recall_at_k(y_true,\n",
    "                         y_pred,\n",
    "                         k: int) -> float:\n",
    "   \n",
    "    if np.sum(y_true) == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    # Sort by predicted values\n",
    "    idx = np.argsort(y_pred)[::-1]\n",
    "    y_true = y_true[idx]\n",
    "    \n",
    "    # Get top k predictions\n",
    "    y_true_at_k = y_true[:k]\n",
    "    \n",
    "    # Use min(k, total_relevant) as denominator\n",
    "    denominator = min(k, np.sum(y_true))\n",
    "    return np.sum(y_true_at_k) / denominator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Heterogeneous Link-level GrahpSAGE GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (movie_lin): Linear(in_features=20, out_features=256, bias=True)\n",
      "  (user_emb): Embedding(609, 256)\n",
      "  (movie_emb): Embedding(9742, 256)\n",
      "  (gnn): GraphModule(\n",
      "    (conv1): ModuleDict(\n",
      "      (user__rates__movie): SAGEConv(256, 256, aggr=mean)\n",
      "      (movie__rev_rates__user): SAGEConv(256, 256, aggr=mean)\n",
      "    )\n",
      "    (conv2): ModuleDict(\n",
      "      (user__rates__movie): SAGEConv(256, 256, aggr=mean)\n",
      "      (movie__rev_rates__user): SAGEConv(256, 256, aggr=mean)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Classifier()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "from torch.nn import  ReLU\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
    "        # Define a 2-layer GNN computation graph.\n",
    "        # Use a *single* `ReLU` non-linearity in-between.\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Our final classifier applies the dot-product between source and destination\n",
    "# node embeddings to derive edge-level predictions:\n",
    "class Classifier(torch.nn.Module):\n",
    "    def forward(self, x_user: Tensor, x_movie: Tensor, edge_label_index: Tensor) -> Tensor:\n",
    "        # Convert node embeddings to edge-level representations:\n",
    "        edge_feat_user = x_user[edge_label_index[0]]\n",
    "        edge_feat_movie = x_movie[edge_label_index[1]]\n",
    "\n",
    "        # Apply dot-product to get a prediction per supervision edge:\n",
    "        return (edge_feat_user * edge_feat_movie).sum(dim=-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        # Since the dataset does not come with rich features, we also learn two\n",
    "        # embedding matrices for users and movies:\n",
    "        self.movie_lin = torch.nn.Linear(20, hidden_channels)\n",
    "        self.user_emb = torch.nn.Embedding(data[\"user\"].num_nodes, hidden_channels)\n",
    "        self.movie_emb = torch.nn.Embedding(data[\"movie\"].num_nodes, hidden_channels)\n",
    "\n",
    "        # Instantiate homogeneous GNN:\n",
    "        self.gnn = GNN(hidden_channels)\n",
    "\n",
    "        # Convert GNN model into a heterogeneous variant:\n",
    "        self.gnn = to_hetero(self.gnn, metadata=data.metadata())\n",
    "\n",
    "        self.classifier = Classifier()\n",
    "\n",
    "    def forward(self, data: HeteroData) -> Tensor:\n",
    "        x_dict = {\n",
    "          \"user\": self.user_emb(data[\"user\"].node_id),\n",
    "          \"movie\": self.movie_lin(data[\"movie\"].x) + self.movie_emb(data[\"movie\"].node_id),\n",
    "        }\n",
    "\n",
    "        # `x_dict` holds feature matrices of all node types\n",
    "        # `edge_index_dict` holds all edge indices of all edge types\n",
    "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
    "\n",
    "        pred = self.classifier(\n",
    "            x_dict[\"user\"],\n",
    "            x_dict[\"movie\"],\n",
    "            data[\"user\", \"rates\", \"movie\"].edge_label_index,\n",
    "        )\n",
    "\n",
    "        return pred\n",
    "\n",
    "model = Model(hidden_channels=256)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Heterogeneous Link-Level GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(pos_pred, neg_pred, neg_sampling_ratio):\n",
    "    # Reshape negative predictions\n",
    "    neg_pred = neg_pred.view(pos_pred.size(0), neg_sampling_ratio)\n",
    "    # Expand positive predictions\n",
    "    pos_pred = pos_pred.unsqueeze(1)\n",
    "    # Compute BPR loss\n",
    "    return -torch.log(torch.sigmoid(pos_pred - neg_pred)).mean()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 1.0365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 0.6212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Loss: 0.5042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Loss: 0.3829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Loss: 0.3248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Loss: 0.3561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Loss: 0.2691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Loss: 0.2209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Loss: 0.2219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss: 0.2191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011, Loss: 0.2011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012, Loss: 0.1840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013, Loss: 0.1660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014, Loss: 0.1549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 015, Loss: 0.1527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 016, Loss: 0.1473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 017, Loss: 0.1454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 018, Loss: 0.1324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 019, Loss: 0.1281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 020, Loss: 0.1257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 021, Loss: 0.1156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 022, Loss: 0.1180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 023, Loss: 0.1098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 024, Loss: 0.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 025, Loss: 0.1071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 026, Loss: 0.1026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 027, Loss: 0.1021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 028, Loss: 0.0969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 029, Loss: 0.0923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 030, Loss: 0.0941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "for epoch in range(1, 31):\n",
    "    total_loss = 0\n",
    "    for sampled_data in tqdm.tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        sampled_data = sampled_data.to(device)\n",
    "        pred = model(sampled_data).to(device)\n",
    "\n",
    "        edge_label = sampled_data['user', 'rates', 'movie'].edge_label.to(device)\n",
    "\n",
    "        pos_pred = pred[edge_label == 1]\n",
    "        neg_pred = pred[edge_label == 0]\n",
    "\n",
    "\n",
    "        loss = bpr_loss(pos_pred, neg_pred, neg_sampling_ratio=2)\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 1.0000\n",
      "Recall@10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "ground_truths = []\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "for sampled_data in tqdm.tqdm(val_loader):\n",
    "    sampled_data = sampled_data.to(device)\n",
    "    pred = model(sampled_data)\n",
    "    ground_truth = sampled_data['user', 'rates', 'movie'].edge_label\n",
    "\n",
    "    preds.append(pred)\n",
    "    ground_truths.append(ground_truth)\n",
    "\n",
    "# Concatenate predictions and ground truths\n",
    "pred = torch.cat(preds, dim=0).cpu().detach().numpy()\n",
    "ground_truth = torch.cat(ground_truths, dim=0).cpu().detach().numpy()\n",
    "\n",
    "# Define your value for k\n",
    "k = 10  # You can modify this value as per your requirement\n",
    "\n",
    "# Calculate precision@k and recall@k\n",
    "precision_k = precision_at_k(ground_truth, pred, k)\n",
    "recall_k = normalized_recall_at_k(ground_truth, pred, k)\n",
    "\n",
    "print(f\"Precision@{k}: {precision_k:.4f}\")\n",
    "print(f\"Recall@{k}: {recall_k:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Assuming val_loader is already defined and contains the validation data\n",
    "model.eval()  # Ensure the model is in evaluation mode\n",
    "\n",
    "recommendations = defaultdict(list)  # Store recommendations for each user\n",
    "\n",
    "for sampled_data in tqdm.tqdm(val_loader):\n",
    "    # Move data to the device the model is on (e.g., GPU)\n",
    "    sampled_data = sampled_data.to(device)\n",
    "    \n",
    "    # Get the predictions from the model\n",
    "    with torch.no_grad():  # Disable gradient calculation for inference\n",
    "        pred = model(sampled_data)\n",
    "    \n",
    "    # Extract ground truth labels (optional, for evaluating) and edge labels for recommendation\n",
    "    user_ids = sampled_data['user', 'rates', 'movie'].edge_label_index[0]  # Users\n",
    "    movie_ids = sampled_data['user', 'rates', 'movie'].edge_label_index[1]  # Movies\n",
    "    \n",
    "    # For each user, store the predicted score and corresponding movie\n",
    "    for i in range(len(user_ids)):\n",
    "        user_id = user_ids[i].item()\n",
    "        movie_id = movie_ids[i].item()\n",
    "        score = pred[i].item()  # Predicted score\n",
    "        \n",
    "        # Append the movie and its score for each user\n",
    "        recommendations[user_id].append((movie_id, score))\n",
    "\n",
    "\n",
    "# Convert them to dictionaries for quick lookup\n",
    "user_id_map = unique_user_id.set_index('mappedID')['userId'].to_dict()\n",
    "movie_id_map = unique_movie_id.set_index('mappedID')['movieId'].to_dict()\n",
    "\n",
    "# Create a list to store the top recommendations in a structured format\n",
    "top_n = 10  # Set how many top movies to recommend for each user\n",
    "recommendation_data = []\n",
    "\n",
    "for mapped_user_id, movie_scores in recommendations.items():\n",
    "    # Sort the list of (movie_id, score) by score in descending order\n",
    "    sorted_recommendations = sorted(movie_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the real user ID using the mapping\n",
    "    real_user_id = user_id_map.get(mapped_user_id)\n",
    "    \n",
    "    # Get the top N movie recommendations\n",
    "    top_movies = sorted_recommendations[:top_n]\n",
    "    \n",
    "    # Append the recommendations for this user to the list\n",
    "    for mapped_movie_id, score in top_movies:\n",
    "        # Get the real movie ID using the mapping\n",
    "        real_movie_id = movie_id_map.get(mapped_movie_id)\n",
    "        \n",
    "        # Append the real IDs and score to the list\n",
    "        recommendation_data.append({\n",
    "            'user_id': real_user_id,\n",
    "            'movie_id': real_movie_id,\n",
    "            'predicted_score': score\n",
    "        })\n",
    "\n",
    "# Convert the list of recommendations to a pandas DataFrame\n",
    "recommendations_df = pd.DataFrame(recommendation_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_df = pd.merge(recommendations_df, movies_df, \n",
    "                                left_on='movie_id', right_on='movieId',\n",
    "                                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
