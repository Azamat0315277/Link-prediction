{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GATConv, to_hetero, HeteroConv\n",
    "from torch_geometric.data import Data, HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download additional libraries\n",
    "%pip install torch-scatter -f https://data.pyg.org/whl/torch-${torch.__version__}.html\n",
    "%pip install torch-sparse -f https://data.pyg.org/whl/torch-${torch.__version__}.html\n",
    "%pip install pyg-lib -f https://data.pyg.org/whl/nightly/torch-${torch.__version__}.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import download_url, extract_zip\n",
    "\n",
    "url = \"https://files.grouplens.org/datasets/movielens/ml-latest.zip\"\n",
    "extract_zip(download_url(url, \".\"), \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movies_path = './ml-latest/movies.csv'\n",
    "ratings_path = './ml-latest/ratings.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check and prerocess movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title  \\\n",
       "movieId                                       \n",
       "1                          Toy Story (1995)   \n",
       "2                            Jumanji (1995)   \n",
       "3                   Grumpier Old Men (1995)   \n",
       "4                  Waiting to Exhale (1995)   \n",
       "5        Father of the Bride Part II (1995)   \n",
       "\n",
       "                                              genres  \n",
       "movieId                                               \n",
       "1        Adventure|Animation|Children|Comedy|Fantasy  \n",
       "2                         Adventure|Children|Fantasy  \n",
       "3                                     Comedy|Romance  \n",
       "4                               Comedy|Drama|Romance  \n",
       "5                                             Comedy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load movie data\n",
    "movies_df = pd.read_csv(movies_path, index_col=\"movieId\")\n",
    "\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         (no genres listed)  Action  Adventure  Animation  Children  Comedy  \\\n",
       "movieId                                                                       \n",
       "1                         0       0          1          1         1       1   \n",
       "2                         0       0          1          0         1       0   \n",
       "3                         0       0          0          0         0       1   \n",
       "4                         0       0          0          0         0       1   \n",
       "5                         0       0          0          0         0       1   \n",
       "\n",
       "         Crime  Documentary  Drama  Fantasy  Film-Noir  Horror  IMAX  Musical  \\\n",
       "movieId                                                                         \n",
       "1            0            0      0        1          0       0     0        0   \n",
       "2            0            0      0        1          0       0     0        0   \n",
       "3            0            0      0        0          0       0     0        0   \n",
       "4            0            0      1        0          0       0     0        0   \n",
       "5            0            0      0        0          0       0     0        0   \n",
       "\n",
       "         Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "movieId                                                    \n",
       "1              0        0       0         0    0        0  \n",
       "2              0        0       0         0    0        0  \n",
       "3              0        1       0         0    0        0  \n",
       "4              0        1       0         0    0        0  \n",
       "5              0        0       0         0    0        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split genres and convert into indicator variables (create dummy variables)\n",
    "genres = movies_df['genres'].str.get_dummies(\"|\")\n",
    "genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User genres as movie input features (node features)\n",
    "movie_features = torch.from_numpy(genres.values).to(torch.float)\n",
    "assert movie_features.size() == (86537, 20) # 20 genres in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>mappedID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  mappedID\n",
       "0        1         0\n",
       "1        2         1\n",
       "2        3         2\n",
       "3        4         3\n",
       "4        5         4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mapping from unique movie indices to range[0, num_movie_nodes]\n",
    "unique_movie_id = pd.DataFrame(data={\n",
    "    'movieId': movies_df.index,\n",
    "    \"mappedID\": pd.RangeIndex(len(movies_df)),\n",
    "})\n",
    "unique_movie_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check and preprocess ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1225734739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1225865086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1225733503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1225735204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>356</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1225735119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1        1     4.0  1225734739\n",
       "1       1      110     4.0  1225865086\n",
       "2       1      158     4.0  1225733503\n",
       "3       1      260     4.5  1225735204\n",
       "4       1      356     5.0  1225735119"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ratings data\n",
    "ratings_df = pd.read_csv(ratings_path)\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>mappedID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  mappedID\n",
       "0       1         0\n",
       "1       2         1\n",
       "2       3         2\n",
       "3       4         3\n",
       "4       5         4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mapping from unique user indices to range [0, num_user_nodes]\n",
    "unique_user_id = ratings_df['userId'].unique()\n",
    "unique_user_id = pd.DataFrame(data={\n",
    "    'userId': unique_user_id,\n",
    "    \"mappedID\": pd.RangeIndex(len(unique_user_id)),\n",
    "})\n",
    "unique_user_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating `edge_index` in COO Format for User-Movie Relationships "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform merge to obtain the edges from users and movies\n",
    "ratings_user_id = pd.merge(ratings_df['userId'], unique_user_id,\n",
    "                            on='userId', how='left')\n",
    "ratings_user_id = torch.from_numpy(ratings_user_id['mappedID'].values)\n",
    "\n",
    "ratings_movie_id = pd.merge(ratings_df['movieId'], unique_movie_id,\n",
    "                            on='movieId', how='left')\n",
    "ratings_movie_id = torch.from_numpy(ratings_movie_id['mappedID'].values)\n",
    "\n",
    "# Create `edge_index` in COO format following PyG semantics\n",
    "edge_index_user_to_movie = torch.stack([ratings_user_id, ratings_movie_id], dim=0)\n",
    "assert edge_index_user_to_movie.size() == (2, 33832162)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of user IDs to consecutive values:\n",
      "==========================================\n",
      "   userId  mappedID\n",
      "0       1         0\n",
      "1       2         1\n",
      "2       3         2\n",
      "3       4         3\n",
      "4       5         4\n"
     ]
    }
   ],
   "source": [
    "print(\"Mapping of user IDs to consecutive values:\")\n",
    "print(\"==========================================\")\n",
    "print(unique_user_id.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of movie IDs to consecutive values:\n",
      "===========================================\n",
      "   movieId  mappedID\n",
      "0        1         0\n",
      "1        2         1\n",
      "2        3         2\n",
      "3        4         3\n",
      "4        5         4\n"
     ]
    }
   ],
   "source": [
    "print(\"Mapping of movie IDs to consecutive values:\")\n",
    "print(\"===========================================\")\n",
    "print(unique_movie_id.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final edge indices pointing from users to movies:\n",
      "=================================================\n",
      "tensor([[     0,      0,      0,  ..., 330974, 330974, 330974],\n",
      "        [     0,    108,    156,  ...,   7911,   7954,   8071]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Final edge indices pointing from users to movies:\")\n",
    "print(\"=================================================\")\n",
    "print(edge_index_user_to_movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating graph based HeteroData (where nodes have different origins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "\n",
    "# Save node indices\n",
    "data['user'].node_id = torch.arange(len(unique_user_id))\n",
    "data['movie'].node_id = torch.arange(len(movies_df))\n",
    "\n",
    "# Add the node features and edge indices\n",
    "data['movie'].x = movie_features\n",
    "\n",
    "data['user', 'rates', 'movie'].edge_index = edge_index_user_to_movie\n",
    "\n",
    "# Also need to make sure add the reverse adges from movies to users\n",
    "# in order to let a GNN model be able to pass messages in both directions.\n",
    "# For this use `ToUndirected()` transform \n",
    "\n",
    "data = T.ToUndirected()(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data\n",
    "\n",
    "assert data.node_types == ['user', 'movie']\n",
    "assert data.edge_types == [(\"user\", \"rates\", \"movie\"),\n",
    "                           (\"movie\", \"rev_rates\", \"user\")]\n",
    "assert data['user'].num_nodes == 330975\n",
    "assert data['user'].num_features == 0\n",
    "assert data['movie'].num_nodes == 86537\n",
    "assert data['movie'].num_features == 20\n",
    "assert data['user', 'rates', 'movie'].num_edges == 33832162\n",
    "assert data['movie','rev_rates', 'user'].num_edges == 33832162\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Edge-level Training Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    disjoint_train_ratio = 0.3,\n",
    "    neg_sampling_ratio = 2.0,\n",
    "    add_negative_train_samples=False,\n",
    "    edge_types = ('user', 'rates', 'movie'),\n",
    "    rev_edge_types = ('movie', 'rev_rates', 'user'),\n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check splits\n",
    "assert train_data['user', 'rates', 'movie'].num_edges == 18946011\n",
    "assert train_data['user', 'rates', 'movie'].edge_label_index.size(1) == 8119719\n",
    "assert train_data['movie', 'rev_rates', 'user'].num_edges == 18946011\n",
    "\n",
    "\n",
    "# No negative edges added:\n",
    "assert train_data[\"user\", \"rates\", \"movie\"].edge_label.min() == 1\n",
    "assert train_data[\"user\", \"rates\", \"movie\"].edge_label.max() == 1\n",
    "\n",
    "assert val_data[\"user\", \"rates\", \"movie\"].num_edges == 27065730\n",
    "assert val_data[\"user\", \"rates\", \"movie\"].edge_label_index.size(1) == 10149648\n",
    "assert val_data[\"movie\", \"rev_rates\", \"user\"].num_edges == 27065730\n",
    "# Negative edges with ratio 2:1:\n",
    "assert val_data[\"user\", \"rates\", \"movie\"].edge_label.long().bincount().tolist() == [6766432, 3383216]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled mini-batch:\n",
      "===================\n",
      "HeteroData(\n",
      "  user={\n",
      "    node_id=[292115],\n",
      "    n_id=[292115],\n",
      "    num_sampled_nodes=[3],\n",
      "  },\n",
      "  movie={\n",
      "    node_id=[86436],\n",
      "    x=[86436, 20],\n",
      "    n_id=[86436],\n",
      "    num_sampled_nodes=[3],\n",
      "  },\n",
      "  (user, rates, movie)={\n",
      "    edge_index=[2, 591852],\n",
      "    edge_label=[786432],\n",
      "    edge_label_index=[2, 786432],\n",
      "    e_id=[591852],\n",
      "    num_sampled_edges=[2],\n",
      "    input_id=[262144],\n",
      "  },\n",
      "  (movie, rev_rates, user)={\n",
      "    edge_index=[2, 4107944],\n",
      "    e_id=[4107944],\n",
      "    num_sampled_edges=[2],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define seed edges:\n",
    "edge_label_index = train_data[\"user\", \"rates\", \"movie\"].edge_label_index\n",
    "edge_label = train_data[\"user\", \"rates\", \"movie\"].edge_label\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,  \n",
    "    num_neighbors=[20, 10],  \n",
    "    neg_sampling_ratio=2.0, \n",
    "    edge_label_index=((\"user\", \"rates\", \"movie\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=262144, # OPtional default= 128\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Inspect a sample:\n",
    "sampled_data = next(iter(train_loader))\n",
    "\n",
    "print(\"Sampled mini-batch:\")\n",
    "print(\"===================\")\n",
    "print(sampled_data)\n",
    "\n",
    "assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label_index.size(1) == 3 * 262144\n",
    "assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label.min() == 0\n",
    "assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label.max() == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Heterogenious Link-level Graph Attention GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATModel(nn.Module):\n",
    "    def __init__(self, hidden_channels, num_user_nodes):\n",
    "        super(GATModel, self).__init__()\n",
    "        # Embedding layer for 'user' nodes (since they have no features)\n",
    "        self.user_embedding = nn.Embedding(num_user_nodes, hidden_channels)\n",
    "        # Linear transformation for 'movie' node features to match hidden_channel\n",
    "        self.movie_lin = nn.Linear(20, hidden_channels)\n",
    "        # Define two GATConv layers for each edge type in the heterogeneous graph\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('user', 'rates', 'movie'): GATConv((-1, -1), hidden_channels, add_self_loops=False),\n",
    "            ('movie', 'rev_rates', 'user'): GATConv((-1, -1), hidden_channels, add_self_loops=False),\n",
    "\n",
    "        }, aggr='mean')\n",
    "\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('user', 'rates', 'movie'): GATConv((-1, -1), hidden_channels, add_self_loops=False),\n",
    "            ('movie', 'rev_rates', 'user'): GATConv((-1, -1), hidden_channels, add_self_loops=False),\n",
    "\n",
    "        }, aggr='mean')\n",
    "        # Edge scoring MLP to compute predictions from node embeddings\n",
    "        self.edge_mlp = nn.Linear(hidden_channels * 2, 1)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        # Retrieve global node IDs for 'user' and 'movie' nodes\n",
    "        user_ids = data['user'].n_id\n",
    "        movie_ids = data['movie'].n_id\n",
    "        # Initialize node features for 'user' and 'movie' nodes\n",
    "        x_dict = {}\n",
    "        x_dict['user'] = self.user_embedding(user_ids)\n",
    "        x_dict['movie'] = self.movie_lin(data['movie'].x)\n",
    "        # Perform GNN message passing through two GATConv layers\n",
    "        x_dict = self.conv1(x_dict, data.edge_index_dict)\n",
    "        x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
    "        x_dict = self.conv2(x_dict, data.edge_index_dict)\n",
    "        x_dict = {key: F.relu(x) for key, x in x_dict.items()}  \n",
    "        # Extract node embeddings for 'user' and 'movie' nodes\n",
    "        user_emb = x_dict['user']\n",
    "        movie_emb = x_dict['movie']\n",
    "        # Get edge indices for which to compute predictions\n",
    "        edge_label_index = data['user', 'rates', 'movie'].edge_label_index\n",
    "        # Get embeddings for source ('user') and target ('movie') nodes\n",
    "        src = user_emb[edge_label_index[0]]\n",
    "        dst = movie_emb[edge_label_index[1]]\n",
    "\n",
    "        # Compute edge scores using an MLP\n",
    "        edge_features = torch.cat([src, dst], dim=-1)\n",
    "        pred = self.edge_mlp(edge_features).squeeze(-1)\n",
    "\n",
    "        return pred\n",
    "\n",
    "num_user_nodes = len(unique_user_id)\n",
    "hidden_channels = 64\n",
    "\n",
    "model = GATModel(hidden_channels=hidden_channels, num_user_nodes=num_user_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(pos_pred, neg_pred, neg_sampling_ratio):\n",
    "    # Reshape negative predictions\n",
    "    neg_pred = neg_pred.view(pos_pred.size(0), neg_sampling_ratio)\n",
    "    # Expand positive predictions\n",
    "    pos_pred = pos_pred.unsqueeze(1)\n",
    "    # Compute BPR loss\n",
    "    return -torch.log(torch.sigmoid(pos_pred - neg_pred)).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:15<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 18.3450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 8.4607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Loss: 3.8165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Loss: 2.7499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Loss: 2.1384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Loss: 1.8695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Loss: 1.7254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Loss: 1.6387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Loss: 1.5639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss: 1.5112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011, Loss: 1.4678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012, Loss: 1.4379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013, Loss: 1.4017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014, Loss: 1.3894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 015, Loss: 1.3685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 016, Loss: 1.3383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 017, Loss: 1.3132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 018, Loss: 1.2942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 019, Loss: 1.2796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 020, Loss: 1.2656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 021, Loss: 1.2483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 022, Loss: 1.2584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 023, Loss: 1.2218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 024, Loss: 1.2043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 025, Loss: 1.1918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 026, Loss: 1.1843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 027, Loss: 1.1724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 028, Loss: 1.1585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:14<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 029, Loss: 1.1522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 31):\n",
    "    total_loss = 0\n",
    "    for sampled_data in tqdm.tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        sampled_data = sampled_data.to(device)\n",
    "        pred = model(sampled_data).to(device)\n",
    "\n",
    "        edge_label = sampled_data['user', 'rates', 'movie'].edge_label.to(device)\n",
    "\n",
    "        pos_pred = pred[edge_label == 1]\n",
    "        neg_pred = pred[edge_label == 0]\n",
    "\n",
    "\n",
    "        loss = bpr_loss(pos_pred, neg_pred, neg_sampling_ratio=2)\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled mini-batch:\n",
      "===================\n",
      "HeteroData(\n",
      "  user={\n",
      "    node_id=[137932],\n",
      "    n_id=[137932],\n",
      "    num_sampled_nodes=[3],\n",
      "  },\n",
      "  movie={\n",
      "    node_id=[29470],\n",
      "    x=[29470, 20],\n",
      "    n_id=[29470],\n",
      "    num_sampled_nodes=[3],\n",
      "  },\n",
      "  (user, rates, movie)={\n",
      "    edge_index=[2, 392333],\n",
      "    edge_label=[262144],\n",
      "    edge_label_index=[2, 262144],\n",
      "    e_id=[392333],\n",
      "    num_sampled_edges=[2],\n",
      "    input_id=[262144],\n",
      "  },\n",
      "  (movie, rev_rates, user)={\n",
      "    edge_index=[2, 2347882],\n",
      "    e_id=[2347882],\n",
      "    num_sampled_edges=[2],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "edge_label_index = val_data['user', 'rates', 'movie'].edge_label_index\n",
    "edge_label = val_data['user', 'rates', 'movie'].edge_label\n",
    "\n",
    "val_loader = LinkNeighborLoader(\n",
    "    data=val_data,\n",
    "    num_neighbors = [20, 10],\n",
    "    edge_label_index = (('user', 'rates', 'movie'), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=262144,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "sampled_data = next(iter(val_loader))\n",
    "print(\"Sampled mini-batch:\")\n",
    "print(\"===================\")\n",
    "print(sampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:09<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.9760\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "preds = []\n",
    "ground_truths = []\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sampled_data in tqdm.tqdm(val_loader):\n",
    "        sampled_data = sampled_data.to(device)\n",
    "        pred = model(sampled_data)\n",
    "        ground_truth = sampled_data['user', 'rates', 'movie'].edge_label.to(device)\n",
    "\n",
    "        # Apply sigmoid to convert logits to probabilities\n",
    "        pred = torch.sigmoid(pred)\n",
    "\n",
    "        preds.append(pred.cpu())\n",
    "        ground_truths.append(ground_truth.cpu())\n",
    "\n",
    "# Concatenate predictions and ground truths\n",
    "pred = torch.cat(preds, dim=0).numpy()\n",
    "ground_truth = torch.cat(ground_truths, dim=0).numpy()\n",
    "\n",
    "# Calculate the AUC score\n",
    "auc = roc_auc_score(ground_truth, pred)\n",
    "\n",
    "print(f\"Validation AUC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [01:39<00:00,  2.56s/it]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Create a dictionary to store recommendations for each user\n",
    "recommendations = defaultdict(list)\n",
    "\n",
    "# Loop over the validation data loader\n",
    "with torch.no_grad():\n",
    "    for sampled_data in tqdm(val_loader):\n",
    "        sampled_data = sampled_data.to(device)\n",
    "        \n",
    "        # Get model predictions\n",
    "        pred = model(sampled_data)\n",
    "        \n",
    "        # Apply sigmoid to convert logits to probabilities if needed\n",
    "        pred = torch.sigmoid(pred).cpu()\n",
    "        \n",
    "        # Extract user and movie IDs from the edge label index\n",
    "        user_ids = sampled_data['user', 'rates', 'movie'].edge_label_index[0].cpu()\n",
    "        movie_ids = sampled_data['user', 'rates', 'movie'].edge_label_index[1].cpu()\n",
    "        \n",
    "        # Loop over the batch and collect predictions\n",
    "        for user_id, movie_id, score in zip(user_ids, movie_ids, pred):\n",
    "            # Convert tensors to scalars\n",
    "            user_id = user_id.item()\n",
    "            movie_id = movie_id.item()\n",
    "            score = score.item()\n",
    "            \n",
    "            # Append the movie and its score for each user\n",
    "            recommendations[user_id].append((movie_id, score))\n",
    "\n",
    "# Map internal IDs back to original user IDs and movie IDs\n",
    "user_id_map = unique_user_id.set_index('mappedID')['userId'].to_dict()\n",
    "movie_id_map = unique_movie_id.set_index('mappedID')['movieId'].to_dict()\n",
    "\n",
    "# Prepare a list to store the top-N recommendations\n",
    "top_n = 10  # Adjust as needed\n",
    "recommendation_data = []\n",
    "\n",
    "for mapped_user_id, movie_scores in recommendations.items():\n",
    "    # Sort the movies for this user by predicted score in descending order\n",
    "    sorted_recommendations = sorted(movie_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the real user ID\n",
    "    real_user_id = user_id_map.get(mapped_user_id)\n",
    "    \n",
    "    # Get the top-N movies\n",
    "    top_movies = sorted_recommendations[:top_n]\n",
    "    \n",
    "    for mapped_movie_id, score in top_movies:\n",
    "        # Get the real movie ID\n",
    "        real_movie_id = movie_id_map.get(mapped_movie_id)\n",
    "        \n",
    "        # Append the recommendation to the list\n",
    "        recommendation_data.append({\n",
    "            'user_id': real_user_id,\n",
    "            'movie_id': real_movie_id,\n",
    "            'predicted_score': score\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the recommendation data\n",
    "recommendations_df = pd.DataFrame(recommendation_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_df = pd.merge(recommendations_df, movies_df, \n",
    "                                left_on='movie_id', right_on='movieId',\n",
    "                                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>predicted_score</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64940</td>\n",
       "      <td>1682</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Truman Show, The (1998)</td>\n",
       "      <td>Comedy|Drama|Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64940</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Twelve Monkeys (a.k.a. 12 Monkeys) (1995)</td>\n",
       "      <td>Mystery|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64940</td>\n",
       "      <td>1028</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mary Poppins (1964)</td>\n",
       "      <td>Children|Comedy|Fantasy|Musical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64940</td>\n",
       "      <td>1027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Robin Hood: Prince of Thieves (1991)</td>\n",
       "      <td>Adventure|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64940</td>\n",
       "      <td>7136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Stolen Kisses (Baisers volés) (1968)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  predicted_score  \\\n",
       "0    64940      1682              1.0   \n",
       "1    64940        32              1.0   \n",
       "2    64940      1028              1.0   \n",
       "3    64940      1027              1.0   \n",
       "4    64940      7136              1.0   \n",
       "\n",
       "                                       title                           genres  \n",
       "0                    Truman Show, The (1998)              Comedy|Drama|Sci-Fi  \n",
       "1  Twelve Monkeys (a.k.a. 12 Monkeys) (1995)          Mystery|Sci-Fi|Thriller  \n",
       "2                        Mary Poppins (1964)  Children|Comedy|Fantasy|Musical  \n",
       "3       Robin Hood: Prince of Thieves (1991)                  Adventure|Drama  \n",
       "4       Stolen Kisses (Baisers volés) (1968)             Comedy|Drama|Romance  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>predicted_score</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1066240</th>\n",
       "      <td>16978</td>\n",
       "      <td>296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>Comedy|Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066241</th>\n",
       "      <td>16978</td>\n",
       "      <td>33</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>Wings of Courage (1995)</td>\n",
       "      <td>Adventure|Romance|IMAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066242</th>\n",
       "      <td>16978</td>\n",
       "      <td>2457</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>Running Scared (1986)</td>\n",
       "      <td>Action|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066243</th>\n",
       "      <td>16978</td>\n",
       "      <td>5187</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>Hopscotch (1980)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066244</th>\n",
       "      <td>16978</td>\n",
       "      <td>650</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>Moll Flanders (1996)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066245</th>\n",
       "      <td>16978</td>\n",
       "      <td>383</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>Wyatt Earp (1994)</td>\n",
       "      <td>Western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066246</th>\n",
       "      <td>16978</td>\n",
       "      <td>551</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>Nightmare Before Christmas, The (1993)</td>\n",
       "      <td>Animation|Children|Fantasy|Musical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066247</th>\n",
       "      <td>16978</td>\n",
       "      <td>4285</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>Frankie and Johnny (1991)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066248</th>\n",
       "      <td>16978</td>\n",
       "      <td>26448</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>Pelle Svanslös (1981)</td>\n",
       "      <td>Animation|Children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066249</th>\n",
       "      <td>16978</td>\n",
       "      <td>5887</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>Another You (1991)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  movie_id  predicted_score  \\\n",
       "1066240    16978       296         1.000000   \n",
       "1066241    16978        33         0.999999   \n",
       "1066242    16978      2457         0.999999   \n",
       "1066243    16978      5187         0.999999   \n",
       "1066244    16978       650         0.999999   \n",
       "1066245    16978       383         0.999999   \n",
       "1066246    16978       551         0.999999   \n",
       "1066247    16978      4285         0.999998   \n",
       "1066248    16978     26448         0.999998   \n",
       "1066249    16978      5887         0.999998   \n",
       "\n",
       "                                          title  \\\n",
       "1066240                     Pulp Fiction (1994)   \n",
       "1066241                 Wings of Courage (1995)   \n",
       "1066242                   Running Scared (1986)   \n",
       "1066243                        Hopscotch (1980)   \n",
       "1066244                    Moll Flanders (1996)   \n",
       "1066245                       Wyatt Earp (1994)   \n",
       "1066246  Nightmare Before Christmas, The (1993)   \n",
       "1066247               Frankie and Johnny (1991)   \n",
       "1066248                   Pelle Svanslös (1981)   \n",
       "1066249                      Another You (1991)   \n",
       "\n",
       "                                     genres  \n",
       "1066240         Comedy|Crime|Drama|Thriller  \n",
       "1066241              Adventure|Romance|IMAX  \n",
       "1066242                       Action|Comedy  \n",
       "1066243                              Comedy  \n",
       "1066244                               Drama  \n",
       "1066245                             Western  \n",
       "1066246  Animation|Children|Fantasy|Musical  \n",
       "1066247                      Comedy|Romance  \n",
       "1066248                  Animation|Children  \n",
       "1066249                              Comedy  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_df[recommendations_df['user_id'].isin([16978])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
